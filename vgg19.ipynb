{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Tomato Bacterial spot': 0, 'Tomato Early blight': 1, 'Tomato Healthy': 2, 'Tomato Late blight': 3, 'Tomato Leaf Mold': 4, 'Tomato Mosaic virus': 5, 'Tomato Septoria leaf spot': 6, 'Tomato Spider mites': 7, 'Tomato Target Spot': 8, 'Tomato Yellow Leaf Curl Virus': 9}\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms,io\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "\n",
    "\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Resize(224),\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.RandomHorizontalFlip(0.2),\n",
    "        transforms.RandomRotation(0.2),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'test': transforms.Compose([\n",
    "        transforms.Resize(224),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(224),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "}\n",
    "\n",
    "root_dir = \"\"\n",
    "image_datasets = {\n",
    "    x: datasets.ImageFolder(os.path.join(root_dir, x), data_transforms[x])\n",
    "    for x in ['train', 'test','val']}\n",
    "dataloaders = {\n",
    "    x: DataLoader(image_datasets[x], batch_size=32, shuffle=True)\n",
    "    for x in ['train', 'test','val']}\n",
    "dataset_sizes = {\n",
    "    x: len(image_datasets[x]) for x in ['train', 'test','val']}\n",
    "\n",
    "class_names = image_datasets['train'].classes\n",
    "\n",
    "label_map = {class_name: i for i, class_name in enumerate(class_names)}\n",
    "\n",
    "print(label_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': <torch.utils.data.dataloader.DataLoader at 0x25db5c55850>,\n",
       " 'test': <torch.utils.data.dataloader.DataLoader at 0x25dbae76060>,\n",
       " 'val': <torch.utils.data.dataloader.DataLoader at 0x25d992ae9f0>}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGG(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(inplace=True)\n",
      "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (6): ReLU(inplace=True)\n",
      "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (8): ReLU(inplace=True)\n",
      "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU(inplace=True)\n",
      "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (13): ReLU(inplace=True)\n",
      "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (15): ReLU(inplace=True)\n",
      "    (16): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (17): ReLU(inplace=True)\n",
      "    (18): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (19): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (20): ReLU(inplace=True)\n",
      "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (22): ReLU(inplace=True)\n",
      "    (23): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (24): ReLU(inplace=True)\n",
      "    (25): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (26): ReLU(inplace=True)\n",
      "    (27): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (29): ReLU(inplace=True)\n",
      "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (31): ReLU(inplace=True)\n",
      "    (32): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (33): ReLU(inplace=True)\n",
      "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (35): ReLU(inplace=True)\n",
      "    (36): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Dropout(p=0.5, inplace=False)\n",
      "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): Dropout(p=0.5, inplace=False)\n",
      "    (6): Sequential(\n",
      "      (0): Linear(in_features=4096, out_features=512, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Dropout(p=0.3, inplace=False)\n",
      "      (3): Linear(in_features=512, out_features=128, bias=True)\n",
      "      (4): ReLU()\n",
      "      (5): Dropout(p=0.2, inplace=False)\n",
      "      (6): Linear(in_features=128, out_features=10, bias=True)\n",
      "      (7): Softmax(dim=1)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models\n",
    "\n",
    "model_ft = models.vgg19(weights='IMAGENET1K_V1')\n",
    "num_ftrs = model_ft.classifier[6].in_features\n",
    "\n",
    "for param in model_ft.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "model_ft.classifier[6] = nn.Sequential(\n",
    "    nn.Linear(num_ftrs, 512),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.3),\n",
    "    nn.Linear(512, 128),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.2),\n",
    "    nn.Linear(128, 10),\n",
    "    nn.Softmax(dim=1)\n",
    ")\n",
    "\n",
    "optimizer = torch.optim.Adam(model_ft.parameters())\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "metrics = ['accuracy']\n",
    "\n",
    "print(model_ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy(target, predicted):\n",
    "    correct = (predicted == target).sum().item()\n",
    "    return correct\n",
    "\n",
    "def val(model, test_data, device):\n",
    "    import numpy as np\n",
    "    model.eval()\n",
    "    not_correct = 0\n",
    "    total_correct = 0\n",
    "    with torch.no_grad():\n",
    "        for batch,(data, target) in enumerate(test_data,start=1):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            pred = model(data)\n",
    "            pred = torch.argmax(pred,dim=1)\n",
    "            correct = calculate_accuracy(target, pred)\n",
    "            total_correct += correct\n",
    "            not_correct += 32-correct\n",
    "            if batch==15:\n",
    "                print(f\"Accuracy: {np.round(total_correct/(total_correct+not_correct),3)} %  |   Loss: {np.round(not_correct/(total_correct+not_correct),3)}   | Correct: {total_correct} | Not Correct: {not_correct}\")\n",
    "                break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(model, train_data):\n",
    "  model.train()\n",
    "  model.to(device)\n",
    "  for b_i,(data, target) in enumerate(train_data,start=1):\n",
    "    data, target = data.to(device), target.to(device)\n",
    "    optimizer.zero_grad()\n",
    "    y_pred = model(data)\n",
    "    loss = criterion(y_pred, target)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if b_i%10==0:\n",
    "      print(f\"Batch = {b_i} | {b_i*len(data)}/{len(train_data.dataset)}   |   Loss = {loss.item()} | \",end=' ')\n",
    "      batch_accuracy(target, y_pred)\n",
    "    if b_i%100==0:\n",
    "      print()\n",
    "      print(\"Validation score\")\n",
    "      val(model, dataloaders['val'], device)\n",
    "def batch_accuracy(target, y_pred):\n",
    "    model_ft.eval()\n",
    "    correct = (torch.argmax(y_pred, dim=1) == target).sum().item()\n",
    "    total = len(target)\n",
    "    accuracy = correct / total * 100\n",
    "    print(f\"Batch accuracy: {accuracy} %\",'\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch = 10 | 320/40960   |   Loss = 2.278470516204834 |  Batch accuracy: 21.875 %\n",
      "Batch = 20 | 640/40960   |   Loss = 2.1442954540252686 |  Batch accuracy: 37.5 %\n",
      "Batch = 30 | 960/40960   |   Loss = 2.1179232597351074 |  Batch accuracy: 34.375 %\n",
      "Batch = 40 | 1280/40960   |   Loss = 1.9473668336868286 |  Batch accuracy: 56.25 %\n",
      "Batch = 50 | 1600/40960   |   Loss = 2.0327260494232178 |  Batch accuracy: 43.75 %\n",
      "Batch = 60 | 1920/40960   |   Loss = 2.047346830368042 |  Batch accuracy: 40.625 %\n",
      "Batch = 70 | 2240/40960   |   Loss = 2.229649543762207 |  Batch accuracy: 21.875 %\n",
      "Batch = 80 | 2560/40960   |   Loss = 1.9982174634933472 |  Batch accuracy: 50.0 %\n",
      "Batch = 90 | 2880/40960   |   Loss = 1.835901141166687 |  Batch accuracy: 68.75 %\n",
      "Batch = 100 | 3200/40960   |   Loss = 1.9472124576568604 |  Batch accuracy: 53.125 %\n",
      "\n",
      "Validation score\n",
      "Accuracy: 0.529 %  |   Loss: 0.471   | Correct: 254 | Not Correct: 226\n",
      "\n",
      "Batch = 110 | 3520/40960   |   Loss = 1.9963104724884033 |  Batch accuracy: 50.0 %\n",
      "Batch = 120 | 3840/40960   |   Loss = 1.9495139122009277 |  Batch accuracy: 46.875 %\n",
      "Batch = 130 | 4160/40960   |   Loss = 1.9918211698532104 |  Batch accuracy: 43.75 %\n",
      "Batch = 140 | 4480/40960   |   Loss = 1.9501969814300537 |  Batch accuracy: 43.75 %\n",
      "Batch = 150 | 4800/40960   |   Loss = 1.7819403409957886 |  Batch accuracy: 68.75 %\n",
      "Batch = 160 | 5120/40960   |   Loss = 1.978648066520691 |  Batch accuracy: 50.0 %\n",
      "Batch = 170 | 5440/40960   |   Loss = 1.9479817152023315 |  Batch accuracy: 53.125 %\n",
      "Batch = 180 | 5760/40960   |   Loss = 1.914149284362793 |  Batch accuracy: 56.25 %\n",
      "Batch = 190 | 6080/40960   |   Loss = 1.706320881843567 |  Batch accuracy: 75.0 %\n",
      "Batch = 200 | 6400/40960   |   Loss = 1.9888606071472168 |  Batch accuracy: 46.875 %\n",
      "\n",
      "Validation score\n",
      "Accuracy: 0.544 %  |   Loss: 0.456   | Correct: 261 | Not Correct: 219\n",
      "\n",
      "Batch = 210 | 6720/40960   |   Loss = 1.943660020828247 |  Batch accuracy: 56.25 %\n",
      "Batch = 220 | 7040/40960   |   Loss = 1.847616195678711 |  Batch accuracy: 59.375 %\n",
      "Batch = 230 | 7360/40960   |   Loss = 1.8707635402679443 |  Batch accuracy: 59.375 %\n",
      "Batch = 240 | 7680/40960   |   Loss = 1.871258020401001 |  Batch accuracy: 62.5 %\n",
      "Batch = 250 | 8000/40960   |   Loss = 1.8194591999053955 |  Batch accuracy: 65.625 %\n",
      "Batch = 260 | 8320/40960   |   Loss = 1.8545514345169067 |  Batch accuracy: 59.375 %\n",
      "Batch = 270 | 8640/40960   |   Loss = 1.8858847618103027 |  Batch accuracy: 59.375 %\n",
      "Batch = 280 | 8960/40960   |   Loss = 1.8625236749649048 |  Batch accuracy: 59.375 %\n",
      "Batch = 290 | 9280/40960   |   Loss = 1.9079935550689697 |  Batch accuracy: 56.25 %\n",
      "Batch = 300 | 9600/40960   |   Loss = 1.888441801071167 |  Batch accuracy: 56.25 %\n",
      "\n",
      "Validation score\n",
      "Accuracy: 0.571 %  |   Loss: 0.429   | Correct: 274 | Not Correct: 206\n",
      "\n",
      "Batch = 310 | 9920/40960   |   Loss = 1.8715643882751465 |  Batch accuracy: 62.5 %\n",
      "Batch = 320 | 10240/40960   |   Loss = 1.8269526958465576 |  Batch accuracy: 65.625 %\n",
      "Batch = 330 | 10560/40960   |   Loss = 1.809048056602478 |  Batch accuracy: 62.5 %\n",
      "Batch = 340 | 10880/40960   |   Loss = 1.9482709169387817 |  Batch accuracy: 53.125 %\n",
      "Batch = 350 | 11200/40960   |   Loss = 1.8047585487365723 |  Batch accuracy: 65.625 %\n",
      "Batch = 360 | 11520/40960   |   Loss = 1.903993844985962 |  Batch accuracy: 56.25 %\n",
      "Batch = 370 | 11840/40960   |   Loss = 1.9102427959442139 |  Batch accuracy: 53.125 %\n",
      "Batch = 380 | 12160/40960   |   Loss = 1.8414239883422852 |  Batch accuracy: 59.375 %\n",
      "Batch = 390 | 12480/40960   |   Loss = 1.92384672164917 |  Batch accuracy: 53.125 %\n",
      "Batch = 400 | 12800/40960   |   Loss = 1.9037412405014038 |  Batch accuracy: 56.25 %\n",
      "\n",
      "Validation score\n",
      "Accuracy: 0.617 %  |   Loss: 0.383   | Correct: 296 | Not Correct: 184\n",
      "\n",
      "Batch = 410 | 13120/40960   |   Loss = 1.8644918203353882 |  Batch accuracy: 59.375 %\n",
      "Batch = 420 | 13440/40960   |   Loss = 2.0193960666656494 |  Batch accuracy: 43.75 %\n",
      "Batch = 430 | 13760/40960   |   Loss = 1.8275612592697144 |  Batch accuracy: 68.75 %\n",
      "Batch = 440 | 14080/40960   |   Loss = 1.8203322887420654 |  Batch accuracy: 68.75 %\n",
      "Batch = 450 | 14400/40960   |   Loss = 1.8435479402542114 |  Batch accuracy: 59.375 %\n",
      "Batch = 460 | 14720/40960   |   Loss = 1.883827567100525 |  Batch accuracy: 59.375 %\n",
      "Batch = 470 | 15040/40960   |   Loss = 1.8365027904510498 |  Batch accuracy: 62.5 %\n",
      "Batch = 480 | 15360/40960   |   Loss = 1.7692780494689941 |  Batch accuracy: 68.75 %\n",
      "Batch = 490 | 15680/40960   |   Loss = 1.9607234001159668 |  Batch accuracy: 46.875 %\n",
      "Batch = 500 | 16000/40960   |   Loss = 1.9730836153030396 |  Batch accuracy: 50.0 %\n",
      "\n",
      "Validation score\n",
      "Accuracy: 0.571 %  |   Loss: 0.429   | Correct: 274 | Not Correct: 206\n",
      "\n",
      "Batch = 510 | 16320/40960   |   Loss = 1.918540358543396 |  Batch accuracy: 56.25 %\n",
      "Batch = 520 | 16640/40960   |   Loss = 1.7437199354171753 |  Batch accuracy: 71.875 %\n",
      "Batch = 530 | 16960/40960   |   Loss = 1.8512312173843384 |  Batch accuracy: 59.375 %\n",
      "Batch = 540 | 17280/40960   |   Loss = 1.869492530822754 |  Batch accuracy: 59.375 %\n",
      "Batch = 550 | 17600/40960   |   Loss = 1.772915005683899 |  Batch accuracy: 68.75 %\n",
      "Batch = 560 | 17920/40960   |   Loss = 1.7604196071624756 |  Batch accuracy: 71.875 %\n",
      "Batch = 570 | 18240/40960   |   Loss = 1.854439377784729 |  Batch accuracy: 62.5 %\n",
      "Batch = 580 | 18560/40960   |   Loss = 1.8866626024246216 |  Batch accuracy: 56.25 %\n",
      "Batch = 590 | 18880/40960   |   Loss = 1.9029260873794556 |  Batch accuracy: 56.25 %\n",
      "Batch = 600 | 19200/40960   |   Loss = 1.8470906019210815 |  Batch accuracy: 62.5 %\n",
      "\n",
      "Validation score\n",
      "Accuracy: 0.617 %  |   Loss: 0.383   | Correct: 296 | Not Correct: 184\n",
      "\n",
      "Batch = 610 | 19520/40960   |   Loss = 1.7693390846252441 |  Batch accuracy: 68.75 %\n",
      "Batch = 620 | 19840/40960   |   Loss = 1.845395565032959 |  Batch accuracy: 59.375 %\n",
      "Batch = 630 | 20160/40960   |   Loss = 1.7417478561401367 |  Batch accuracy: 75.0 %\n",
      "Batch = 640 | 20480/40960   |   Loss = 1.8459552526474 |  Batch accuracy: 59.375 %\n",
      "Batch = 650 | 20800/40960   |   Loss = 1.779723882675171 |  Batch accuracy: 65.625 %\n",
      "Batch = 660 | 21120/40960   |   Loss = 1.8220518827438354 |  Batch accuracy: 65.625 %\n",
      "Batch = 670 | 21440/40960   |   Loss = 1.7504056692123413 |  Batch accuracy: 68.75 %\n",
      "Batch = 680 | 21760/40960   |   Loss = 1.6253105401992798 |  Batch accuracy: 84.375 %\n",
      "Batch = 690 | 22080/40960   |   Loss = 1.7669838666915894 |  Batch accuracy: 71.875 %\n",
      "Batch = 700 | 22400/40960   |   Loss = 1.8519824743270874 |  Batch accuracy: 62.5 %\n",
      "\n",
      "Validation score\n",
      "Accuracy: 0.629 %  |   Loss: 0.371   | Correct: 302 | Not Correct: 178\n",
      "\n",
      "Batch = 710 | 22720/40960   |   Loss = 1.8471449613571167 |  Batch accuracy: 62.5 %\n",
      "Batch = 720 | 23040/40960   |   Loss = 1.7413136959075928 |  Batch accuracy: 71.875 %\n",
      "Batch = 730 | 23360/40960   |   Loss = 1.771438479423523 |  Batch accuracy: 68.75 %\n",
      "Batch = 740 | 23680/40960   |   Loss = 1.8111275434494019 |  Batch accuracy: 65.625 %\n",
      "Batch = 750 | 24000/40960   |   Loss = 1.8542940616607666 |  Batch accuracy: 59.375 %\n",
      "Batch = 760 | 24320/40960   |   Loss = 1.8452272415161133 |  Batch accuracy: 59.375 %\n",
      "Batch = 770 | 24640/40960   |   Loss = 1.7919481992721558 |  Batch accuracy: 68.75 %\n",
      "Batch = 780 | 24960/40960   |   Loss = 1.710172414779663 |  Batch accuracy: 75.0 %\n",
      "Batch = 790 | 25280/40960   |   Loss = 1.9126085042953491 |  Batch accuracy: 53.125 %\n",
      "Batch = 800 | 25600/40960   |   Loss = 1.7621281147003174 |  Batch accuracy: 68.75 %\n",
      "\n",
      "Validation score\n",
      "Accuracy: 0.671 %  |   Loss: 0.329   | Correct: 322 | Not Correct: 158\n",
      "\n",
      "Batch = 810 | 25920/40960   |   Loss = 1.795486569404602 |  Batch accuracy: 65.625 %\n",
      "Batch = 820 | 26240/40960   |   Loss = 1.898353934288025 |  Batch accuracy: 56.25 %\n",
      "Batch = 830 | 26560/40960   |   Loss = 1.6562457084655762 |  Batch accuracy: 81.25 %\n",
      "Batch = 840 | 26880/40960   |   Loss = 1.993371605873108 |  Batch accuracy: 46.875 %\n",
      "Batch = 850 | 27200/40960   |   Loss = 1.7521313428878784 |  Batch accuracy: 71.875 %\n",
      "Batch = 860 | 27520/40960   |   Loss = 1.7694240808486938 |  Batch accuracy: 68.75 %\n",
      "Batch = 870 | 27840/40960   |   Loss = 1.7166014909744263 |  Batch accuracy: 75.0 %\n",
      "Batch = 880 | 28160/40960   |   Loss = 1.7990235090255737 |  Batch accuracy: 65.625 %\n",
      "Batch = 890 | 28480/40960   |   Loss = 1.746854543685913 |  Batch accuracy: 71.875 %\n",
      "Batch = 900 | 28800/40960   |   Loss = 1.933403730392456 |  Batch accuracy: 50.0 %\n",
      "\n",
      "Validation score\n",
      "Accuracy: 0.669 %  |   Loss: 0.331   | Correct: 321 | Not Correct: 159\n",
      "\n",
      "Batch = 910 | 29120/40960   |   Loss = 1.8515541553497314 |  Batch accuracy: 62.5 %\n",
      "Batch = 920 | 29440/40960   |   Loss = 1.8366074562072754 |  Batch accuracy: 62.5 %\n",
      "Batch = 930 | 29760/40960   |   Loss = 1.7980132102966309 |  Batch accuracy: 65.625 %\n",
      "Batch = 940 | 30080/40960   |   Loss = 1.8020991086959839 |  Batch accuracy: 65.625 %\n",
      "Batch = 950 | 30400/40960   |   Loss = 1.8669356107711792 |  Batch accuracy: 59.375 %\n",
      "Batch = 960 | 30720/40960   |   Loss = 1.8310595750808716 |  Batch accuracy: 65.625 %\n",
      "Batch = 970 | 31040/40960   |   Loss = 1.8356742858886719 |  Batch accuracy: 62.5 %\n",
      "Batch = 980 | 31360/40960   |   Loss = 1.8933758735656738 |  Batch accuracy: 56.25 %\n",
      "Batch = 990 | 31680/40960   |   Loss = 1.8691505193710327 |  Batch accuracy: 56.25 %\n",
      "Batch = 1000 | 32000/40960   |   Loss = 1.951424241065979 |  Batch accuracy: 50.0 %\n",
      "\n",
      "Validation score\n",
      "Accuracy: 0.648 %  |   Loss: 0.352   | Correct: 311 | Not Correct: 169\n",
      "\n",
      "Batch = 1010 | 32320/40960   |   Loss = 1.8143349885940552 |  Batch accuracy: 65.625 %\n",
      "Batch = 1020 | 32640/40960   |   Loss = 1.8399831056594849 |  Batch accuracy: 62.5 %\n",
      "Batch = 1030 | 32960/40960   |   Loss = 1.856998085975647 |  Batch accuracy: 62.5 %\n",
      "Batch = 1040 | 33280/40960   |   Loss = 1.8365429639816284 |  Batch accuracy: 65.625 %\n",
      "Batch = 1050 | 33600/40960   |   Loss = 1.7602403163909912 |  Batch accuracy: 71.875 %\n",
      "Batch = 1060 | 33920/40960   |   Loss = 1.7972257137298584 |  Batch accuracy: 65.625 %\n",
      "Batch = 1070 | 34240/40960   |   Loss = 1.6897131204605103 |  Batch accuracy: 78.125 %\n",
      "Batch = 1080 | 34560/40960   |   Loss = 1.9437644481658936 |  Batch accuracy: 50.0 %\n",
      "Batch = 1090 | 34880/40960   |   Loss = 1.7762110233306885 |  Batch accuracy: 68.75 %\n",
      "Batch = 1100 | 35200/40960   |   Loss = 1.583444356918335 |  Batch accuracy: 87.5 %\n",
      "\n",
      "Validation score\n",
      "Accuracy: 0.74 %  |   Loss: 0.26   | Correct: 355 | Not Correct: 125\n",
      "\n",
      "Batch = 1110 | 35520/40960   |   Loss = 1.7102622985839844 |  Batch accuracy: 75.0 %\n",
      "Batch = 1120 | 35840/40960   |   Loss = 1.892055630683899 |  Batch accuracy: 56.25 %\n",
      "Batch = 1130 | 36160/40960   |   Loss = 1.7806504964828491 |  Batch accuracy: 68.75 %\n",
      "Batch = 1140 | 36480/40960   |   Loss = 1.7828257083892822 |  Batch accuracy: 65.625 %\n",
      "Batch = 1150 | 36800/40960   |   Loss = 1.822251796722412 |  Batch accuracy: 62.5 %\n",
      "Batch = 1160 | 37120/40960   |   Loss = 1.8197267055511475 |  Batch accuracy: 62.5 %\n",
      "Batch = 1170 | 37440/40960   |   Loss = 1.8474076986312866 |  Batch accuracy: 62.5 %\n",
      "Batch = 1180 | 37760/40960   |   Loss = 1.882933259010315 |  Batch accuracy: 59.375 %\n",
      "Batch = 1190 | 38080/40960   |   Loss = 1.7993489503860474 |  Batch accuracy: 65.625 %\n",
      "Batch = 1200 | 38400/40960   |   Loss = 1.7730040550231934 |  Batch accuracy: 68.75 %\n",
      "\n",
      "Validation score\n",
      "Accuracy: 0.675 %  |   Loss: 0.325   | Correct: 324 | Not Correct: 156\n",
      "\n",
      "Batch = 1210 | 38720/40960   |   Loss = 1.7509526014328003 |  Batch accuracy: 71.875 %\n",
      "Batch = 1220 | 39040/40960   |   Loss = 1.7764196395874023 |  Batch accuracy: 68.75 %\n",
      "Batch = 1230 | 39360/40960   |   Loss = 1.7240841388702393 |  Batch accuracy: 75.0 %\n",
      "Batch = 1240 | 39680/40960   |   Loss = 1.7592926025390625 |  Batch accuracy: 71.875 %\n",
      "Batch = 1250 | 40000/40960   |   Loss = 1.9608702659606934 |  Batch accuracy: 50.0 %\n",
      "Batch = 1260 | 40320/40960   |   Loss = 1.6486611366271973 |  Batch accuracy: 81.25 %\n",
      "Batch = 1270 | 40640/40960   |   Loss = 1.8278847932815552 |  Batch accuracy: 62.5 %\n",
      "Batch = 1280 | 40960/40960   |   Loss = 1.8013402223587036 |  Batch accuracy: 65.625 %\n"
     ]
    }
   ],
   "source": [
    "training(model_ft,dataloaders['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy(target, predicted):\n",
    "    correct = (predicted == target).sum().item()\n",
    "    return correct\n",
    "\n",
    "def test(model, test_data, device):\n",
    "    import numpy as np\n",
    "    model.eval()\n",
    "    not_correct = 0\n",
    "    total_correct = 0\n",
    "    with torch.no_grad():\n",
    "        for batch,(data, target) in enumerate(test_data,start=1):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            pred = model(data)\n",
    "            pred = torch.argmax(pred,dim=1)\n",
    "            correct = calculate_accuracy(target, pred)\n",
    "            total_correct += correct\n",
    "            not_correct += 32-correct\n",
    "        print(f\"Accuracy: {np.round(total_correct/(total_correct+not_correct),3)} %  |   Loss: {np.round(not_correct/(total_correct+not_correct),3)}   | Correct: {total_correct} | Not Correct: {not_correct}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.68 %  |   Loss: 0.32   | Correct: 6963 | Not Correct: 3277\n"
     ]
    }
   ],
   "source": [
    "test(model_ft, dataloaders['test'], device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.671 %  |   Loss: 0.329   | Correct: 4124 | Not Correct: 2020\n"
     ]
    }
   ],
   "source": [
    "test(model_ft, dataloaders['val'], device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved trained model as vgg16_model.h5 \n"
     ]
    }
   ],
   "source": [
    "torch.save(model_ft.state_dict(), 'vgg16_model.h5')\n",
    "print('Saved trained model as %s ' % 'vgg16_model.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
